{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust images\n",
    "def image_to_base64(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    output_buffer = BytesIO()\n",
    "    img.save(output_buffer, format='JPEG')\n",
    "    byte_data = output_buffer.getvalue()\n",
    "    base64_str = base64.b64encode(byte_data)\n",
    "    return base64_str\n",
    "def base64_to_image(base64_str, image_path=None):\n",
    "    byte_data = base64.b64decode(base64_str)\n",
    "    image_data = BytesIO(byte_data)\n",
    "    img = Image.open(image_data)\n",
    "    if image_path:\n",
    "        img.save(image_path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if the rgb of mask area is over 185 then return false\n",
    "def video_check_light(im,mask,gate):\n",
    "    flag=True\n",
    "    img=cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    img = np.array(img)\n",
    "    count=0\n",
    "    for i,j in zip(np.where(mask == 1)[0],np.where(mask == 1)[1]):\n",
    "        count+=img[i,j].sum()\n",
    "    print((count/3)/np.where(mask == 1)[0].shape[0])\n",
    "    if ((count/3)/np.where(mask == 1)[0].shape[0])>=gate:\n",
    "        flag=False\n",
    "    return flag\n",
    "\n",
    "\n",
    "def random_colors(N):\n",
    "    np.random.seed(1)\n",
    "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
    "    return colors\n",
    "\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate area here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "\n",
    "    pixel_clip=-1 #Initialize the true area of each point\n",
    "    for count, color in enumerate(colors):\n",
    "        if names[ids[count]]==\"clip\":\n",
    "            y1, x1, y2, x2 = boxes[count]\n",
    "            side_length_pixel=7*7/((x2-x1)**2+(y2-y1)**2)\n",
    "            pixel_clip = side_length_pixel         #true area of each point\n",
    "            \n",
    "            diagonal = ((x2-x1)**2+(y2-y1)**2)**0.5\n",
    "            true_diagonal = 7/diagonal\n",
    "            break\n",
    "\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "\n",
    "        if label == \"hole\":\n",
    "            continue\n",
    "        \n",
    "        score = scores[i] if scores is not None else None\n",
    "\n",
    "\n",
    "        mask = masks[:, :, i]\n",
    "        total_area = mask.shape[0]*mask.shape[1] #total area of image\n",
    "        mask_percentage = np.count_nonzero(mask)/total_area\n",
    "\n",
    "        diagonal_label=\"\"\n",
    "        area_label=\"\"\n",
    "        if pixel_clip==-1 and label == \"polyp\":     #No clips show how % of the whole picture   \n",
    "            area_label=\"areaperc:\" + str(round(mask_percentage*100,4))+\"%\"\n",
    "        elif pixel_clip!=-1 and label == \"polyp\":   #with clip then show mm2\n",
    "            polyp_diagonal = true_diagonal*((x2-x1)**2+(y2-y1)**2)**0.5\n",
    "            area_label=\"realarea:\" + str(round(np.count_nonzero(mask)*pixel_clip,2))+\" mm2\"\n",
    "            diagonal_label=\"diagonal=\" + str(round(polyp_diagonal,2)) + \"mm\"\n",
    "\n",
    "        label = label + \" conf:\"\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "\n",
    "\n",
    "        if video_check_light(image,mask,gate=125):  #use video_check_light if don't needed just delete\n",
    "            image = apply_mask(image, mask, color)\n",
    "            image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "            image = cv2.putText(\n",
    "                image, caption, (x1, y1-44), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "            )\n",
    "            image = cv2.putText(\n",
    "                image, area_label, (x1, y1-23), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "            )\n",
    "            image = cv2.putText(\n",
    "                image, diagonal_label, (x1, y1-2), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "            )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"logs\\\\your_model.h5\")\n",
    "\n",
    "\n",
    "class InferenceConfig(Config):\n",
    "    NAME = \"polyp\"\n",
    "    NUM_CLASSES = 1 + 2\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "    TRAIN_ROIS_PER_IMAGE =100\n",
    "    STEPS_PER_EPOCH = 200\n",
    "    VALIDATION_STEPS = 50\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "model = modellib.MaskRCNN(\n",
    "    mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
    ")\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# Class names firsth one should be BG background\n",
    "class_names = ['BG','polyp', 'clip']  #'hole']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = '10.1.202.132'  #host ip address\n",
    "PORT = 8000\n",
    "\n",
    "server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server.bind((HOST, PORT))\n",
    "server.listen(10)\n",
    "\n",
    "while True:\n",
    "    conn, addr = server.accept()\n",
    "    recieve  = conn.recv(99999999999)\n",
    "    img = base64_to_image(recieve)     #change image format\n",
    "    \n",
    "    #predict\n",
    "    ##################################################################\n",
    "    results = model.detect([np.array(img)], verbose=0)\n",
    "    r = results[0]\n",
    "    frame = display_instances(\n",
    "        np.array(img), r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
    "    )\n",
    "    Image.fromarray(frame).save(\"temp.jpg\")     #save the result\n",
    "    ##################################################################\n",
    "    \n",
    "    conn.sendall(image_to_base64(\"temp.jpg\"))#serverMessage.encode())\n",
    "    conn.close()\n",
    "\n",
    "#server.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
