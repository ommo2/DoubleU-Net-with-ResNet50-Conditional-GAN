{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from mrcnn.config import Config\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    " \n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    " \n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"logs\",\"mask_rcnn_polyp_0055.h5\")\n",
    "    \n",
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the polyp dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"polyp\"\n",
    "\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 2  # background + 1 shapes\n",
    "\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "    # anchors size should be the same size while training\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "    \n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 100\n",
    "\n",
    "    STEPS_PER_EPOCH = 200   \n",
    "    VALIDATION_STEPS = 50\n",
    "\n",
    "config = ShapesConfig()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    " \n",
    "# Class names firsth one should be BG background\n",
    "class_names = ['BG','polyp','clip']\n",
    "\n",
    "\n",
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite some function\n",
    "class PolypDataset(utils.Dataset):\n",
    "    # Get how many instances (objects) there are in this figure\n",
    "    def get_obj_index(self, image):\n",
    "        n = np.max(image)\n",
    "        return n\n",
    "\n",
    "    # Parse the yaml file obtained from labelme to get the instance labels for each layer of the mask\n",
    "    def from_yaml_get_class(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        with open(info['yaml_path']) as f:\n",
    "            temp = yaml.load(f.read())\n",
    "            labels = temp['label_names']\n",
    "            del labels[0]\n",
    "        return labels\n",
    "\n",
    "    # Rewrite draw_mask\n",
    "    def draw_mask(self, num_obj, mask, image, image_id):\n",
    "        # print(\"draw_mask-->\",image_id)\n",
    "        # print(\"self.image_info\",self.image_info)\n",
    "        info = self.image_info[image_id]\n",
    "        # print(\"info-->\",info)\n",
    "        # print(\"info[width]----->\",info['width'],\"-info[height]--->\",info['height'])\n",
    "        for index in range(num_obj):\n",
    "            for i in range(info['width']):\n",
    "                for j in range(info['height']):\n",
    "                    # print(\"image_id-->\",image_id,\"-i--->\",i,\"-j--->\",j)\n",
    "                    # print(\"info[width]----->\",info['width'],\"-info[height]--->\",info['height'])\n",
    "                    at_pixel = image.getpixel((i, j))\n",
    "                    if at_pixel == index + 1:\n",
    "                        mask[j, i, index] = 1\n",
    "        return mask\n",
    "\n",
    "    # Rewrite load_shapes to include your own categories\n",
    "    # and added path, mask_path, yaml_path to self.image_info information\n",
    "    def load_shapes(self, count, img_folder, mask_folder, imglist, dataset_root_path, yaml_folder):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"polyp\", 1, \"polyp\")\n",
    "        self.add_class(\"polyp\", 2, \"clip\")\n",
    "        #self.add_class(\"shapes\", 3, \"hole\")\n",
    "\n",
    "        for i in range(count):\n",
    "            # Get image width and height\n",
    "            print(i)\n",
    "            filestr = imglist[i].split(\".\")[0]\n",
    "            # print(imglist[i],\"-->\",cv_img.shape[1],\"--->\",cv_img.shape[0])\n",
    "            # print(\"id-->\", i, \" imglist[\", i, \"]-->\", imglist[i],\"filestr-->\",filestr)\n",
    "            # filestr = filestr.split(\"_\")[1]\n",
    "            mask_path = mask_folder + \"/\" + imglist[i]\n",
    "            print(mask_path)\n",
    "            yaml_path = yaml_folder + \"/\" + filestr + \".yaml\"\n",
    "            print(img_folder + \"/\" + imglist[i])\n",
    "            cv_img = cv2.imread(img_folder + \"/\" + imglist[i])\n",
    "            self.add_image(\"polyp\", image_id=i, path=img_folder + \"/\" + imglist[i],\n",
    "                           width=cv_img.shape[1], height=cv_img.shape[0], mask_path=mask_path, yaml_path=yaml_path)\n",
    "\n",
    "\n",
    "    # Rewrite load_mask\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        global iter_num\n",
    "        print(\"image_id\", image_id)\n",
    "        info = self.image_info[image_id]\n",
    "        count = 1  # number of object\n",
    "        img = Image.open(info['mask_path'])\n",
    "        num_obj = self.get_obj_index(img)\n",
    "        mask = np.zeros([info['height'], info['width'], num_obj], dtype=np.uint8)\n",
    "        mask = self.draw_mask(num_obj, mask, img, image_id)\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        labels = []\n",
    "        labels = self.from_yaml_get_class(image_id)\n",
    "\n",
    "        labels_form = []\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i].find(\"polyp\") != -1:            #add your class here\n",
    "                labels_form.append(\"polyp\")\n",
    "            elif labels[i].find(\"clip\") != -1:\n",
    "                labels_form.append(\"clip\")\n",
    "            #elif labels[i].find(\"hole\") != -1:\n",
    "            #    labels_form.append(\"hole\")\n",
    "\n",
    "        class_ids = np.array([self.class_names.index(s) for s in labels_form])\n",
    "        return mask, class_ids.astype(np.int32)\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size * cols, size * rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = \"./\"\n",
    "img_folder = dataset_root_path + \"../img_folder/test\"\n",
    "mask_folder = dataset_root_path + \"../mask_folder/test\" \n",
    "yaml_folder = dataset_root_path + \"../yaml_folder/test\"\n",
    "imglist = os.listdir(img_folder)\n",
    "count = len(imglist)\n",
    "\n",
    "# train and val dataset preparation\n",
    "dataset_test = PolypDataset()\n",
    "dataset_test.load_shapes(count, img_folder, mask_folder, imglist, dataset_root_path,yaml_folder)\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import yaml\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_test.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_test.load_image(image_id)\n",
    "    mask, class_ids = dataset_test.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_test.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "image_ids = dataset_test.image_ids\n",
    "APs = []\n",
    "F1_scores = []\n",
    "total_recalls = []\n",
    "total_precisions = []\n",
    "ious=[]\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_test, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    \n",
    "    total_recalls.append(np.mean(recalls))\n",
    "    total_precisions.append(np.mean(precisions))\n",
    "    F1_scores.append((2* (np.mean(precisions) * np.mean(recalls)))/(np.mean(precisions) + np.mean(recalls)))\n",
    "    APs.append(AP)\n",
    "    ious.append(np.nan_to_num(np.mean(overlaps).astype(np.float64)))\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))\n",
    "print(\"recalls: \", np.mean(total_recalls))\n",
    "print(\"precisions: \", np.mean(total_precisions))\n",
    "print(\"F1_scores: \", np.mean(F1_scores))\n",
    "print(\"IOUs: \", np.mean(ious))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
